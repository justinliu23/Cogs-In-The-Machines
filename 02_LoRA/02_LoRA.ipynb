{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868e6bd3-7d6d-4e9e-a826-a05ae66f3bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LlamaForCausalLM, pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from trl import DataCollatorForCompletionOnlyLM, SFTConfig, SFTTrainer\n",
    "from peft import AdaLoRAConfig, LoraConfig, PeftModel, TaskType, get_peft_model\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af0ce12-d498-4dee-8da3-8217ef3de043",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", legacy=False, device_map = \"cuda\")\n",
    "PAD_TOKEN = \"<|pad|>\"\n",
    "tokenizer.add_special_tokens({\"pad_token\": PAD_TOKEN})\n",
    "tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289f609-fe26-4542-a454-97cc1af3eb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\", device_map=\"cuda\")\n",
    "model.resize_token_embeddings(len(tokenizer), pad_to_multiple_of=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60334aea-64be-4d82-ab47-5a6dc1880ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"train\": \"train.json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f879969-ce69-4e79-95cf-31346d5be4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_template = \"<|end_header_id|>\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "\n",
    "examples = [dataset['train'][i]['text'] for i in range(len(dataset['train']))]\n",
    "encodings = [tokenizer(e) for e in examples]\n",
    "\n",
    "dataloader = DataLoader(encodings, collate_fn=collator, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adad3e7f-6f11-409e-ad70-9d9b2847944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r = 32,\n",
    "    lora_alpha = 16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attno_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\"\n",
    "    ],\n",
    "    lora_dropout = 0.05,\n",
    "    bias = \"none\",\n",
    "    task_type = TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f959bd-4668-497d-991e-430205f69f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = SFTConfig(\n",
    "    output_dir = \"finetuned/\",\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = 512,\n",
    "    per_device_train_batch_size = 2,\n",
    "    num_train_epochs = 1, ###\n",
    "    learning_rate = 1e-4, ###\n",
    "    bf16 = True,\n",
    "    save_safetensors = False,\n",
    "    dataset_kwargs = {\n",
    "        \"add_special_tokens\" : False,\n",
    "        \"append_concat_token\" : False\n",
    "    },\n",
    "    seed = 17\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    args = sft_config,\n",
    "    train_dataset = dataset[\"train\"],\n",
    "    eval_dataset = None,\n",
    "    tokenizer = tokenizer,\n",
    "    data_collator = collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb7be5e-6f5e-4c91-b84a-5563403a4dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8de46b-38c1-43ad-a7d9-c1ebfff64ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b815fd4-3e16-46a2-8d03-10ad12cff640",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save_pretrained(\"finetuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b827dee5-d964-4e72-9a56-cb2d8cfec599",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    task = \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    max_new_tokens = 32,\n",
    "    return_full_text = True,\n",
    "    top_k = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319d9383-34b0-4d39-9e26-85d6bf8cd601",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"test\": \"holdout_test.json\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00649c-3505-4044-b1c7-5a2d128bd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "for i in tqdm(range(len(dataset['test']))):\n",
    "    text = dataset['test'][i]['text']\n",
    "    cutout = -1\n",
    "    for j in range(len(text), 16, -1):\n",
    "        snippet = text[j - 17:j]\n",
    "        if snippet == '<|end_header_id|>':\n",
    "            cutout = j\n",
    "            break\n",
    "    prompt = text[:j]\n",
    "    output = pipe(prompt)[0]['generated_text'] + '<|eot_id|>'\n",
    "    if text == output:\n",
    "        correct += 1\n",
    "\n",
    "print(\"Score:\", correct / len(dataset['test']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
